@inject IJSRuntime Js

<!-- Chat Container -->
<MudContainer MaxWidth="MaxWidth.Medium" Class="full-height-chat">
    @if (Ollama is not null && !string.IsNullOrWhiteSpace(Ollama.SelectedModel))
    {
        <MudAlert Severity="Severity.Normal">Starting a chat with <b>@Ollama.SelectedModel</b></MudAlert>
    }
    @foreach (var chatBubble in chatBubbles)
    {
        <MudPaper Class="@chatBubble.GetClass()">
            @if (!string.IsNullOrWhiteSpace(chatBubble.PromptText))
            {
                <MudText>@(chatBubble.PromptText)</MudText>
            }
            @if (!string.IsNullOrWhiteSpace(chatBubble.ThinkText))
            {
                <MudText>@((MarkupString)chatBubble.ThinkText)</MudText><br/>
            }
            @if (!string.IsNullOrWhiteSpace(chatBubble.ResponseText))
            {
                <MudMarkdown Value="@chatBubble.ResponseText" CodeBlockTheme="CodeBlockTheme.Dark"/>
            }
        </MudPaper>
    }
    @if (!string.IsNullOrWhiteSpace(streamingResponse))
    {
        // Display streaming response here. When the response is complete, it will be added to the chat collection
        <MudPaper Class="chat-bubble chat-bubble-bot">
            @if (!string.IsNullOrWhiteSpace(thinkResponse))
            {
                <MudText>@((MarkupString)thinkResponse)</MudText><br/>
            }
            @if (!string.IsNullOrWhiteSpace(markdownResponse))
            {
                <MudMarkdown Value="@markdownResponse" CodeBlockTheme="CodeBlockTheme.Dark"/>
            }
        </MudPaper>
    }
</MudContainer>

<!-- Prompt Container -->
<MudContainer MaxWidth="MaxWidth.Medium" Class="fixed-bottom-prompt">
    <MudGrid Justify="Justify.Center">
        <MudItem xs="10">
            <MudTextField T="string" Label="Enter Your Prompt" Lines="3" Variant="Variant.Outlined"
                          @bind-value="prompt" Disabled="thinking" />
        </MudItem>
        <MudItem xs="2" Class="d-flex align-center justify-center mud-width-full">
            @if (thinking || Ollama is null || string.IsNullOrWhiteSpace(Ollama.SelectedModel))
            {
                <MudProgressCircular Color="Color.Primary" Size="Size.Small" Indeterminate="true"/>
            }
            else
            {
                <MudButton Variant="Variant.Filled" Color="Color.Dark" FullWidth="true" Style="height: 80px"
                           StartIcon="@Icons.Material.Filled.PlayArrow" IconColor="Color.Tertiary"
                           Disabled="thinking || Ollama is null" OnClick="SubmitPrompt">
                    Submit
                </MudButton>
            }
        </MudItem>
    </MudGrid>
</MudContainer>

@code {
    [Parameter] public OllamaApiClient? Ollama { get; set; }
    
    private Chat? chat;
    private IEnumerable<ChatBubble> chatBubbles = new List<ChatBubble>();
    
    private string prompt = "Tell me something good";
    private string streamingResponse = string.Empty;
    private string thinkResponse = string.Empty;
    private string markdownResponse = string.Empty;
    
    private bool thinking = false;

    public void SetSelectedModel(string model)
    {
        if (Ollama is null) return;
        Ollama.SelectedModel = model;
        chat = new Chat(Ollama);
        chatBubbles = new List<ChatBubble>();
    }
    
    private async Task SubmitPrompt()
    {
        if (Ollama is null) return;
        
        thinking = true;
        streamingResponse = "";
        chat ??= new Chat(Ollama);

        chatBubbles = chatBubbles.Append(new ChatBubble
        {
            PromptText = prompt,
            IsUser = true
        });
        
        await foreach (var answerToken in chat.SendAsync(prompt))
        {
            streamingResponse += answerToken;
            markdownResponse = streamingResponse;
            ProcessStreamingResponse();
            StateHasChanged();
            await ScrollToBottom();
        }
        
        var responseBubble = new ChatBubble
        {
            ThinkText = thinkResponse,
            ResponseText = markdownResponse,
            IsUser = false
        };
        
        chatBubbles = chatBubbles.Append(responseBubble);
        
        // Reset prompt and response
        streamingResponse = markdownResponse = thinkResponse = prompt = "";
        thinking = false;
    }
    
    /// <summary>
    /// For models that sometimes include a <think>response</think> block, this method will separate that section from
    /// the rest of the response. These sections do not always display correctly with MudMarkdown, so they must be
    /// handled differently.
    /// </summary>
    private void ProcessStreamingResponse()
    {
        thinkResponse = "";
        markdownResponse = streamingResponse;
        
        if (string.IsNullOrWhiteSpace(streamingResponse)) return;
        var startIndex = streamingResponse.IndexOf("<think>", StringComparison.OrdinalIgnoreCase);
        if (startIndex == -1) return;
        var endIndex = streamingResponse.IndexOf("</think>", startIndex, StringComparison.OrdinalIgnoreCase);
        if (endIndex != -1)
        {
            endIndex += "</think>".Length;
            thinkResponse = streamingResponse.Substring(startIndex, endIndex - startIndex);
            markdownResponse = streamingResponse.Remove(startIndex, endIndex - startIndex);
        }
        else
        {
            thinkResponse = streamingResponse[startIndex..];
            markdownResponse = streamingResponse.Remove(startIndex);
        }
        
        thinkResponse = EncodeHtmlTags(thinkResponse);
        thinkResponse = thinkResponse.Replace("\n", "<br/>");
    }
    
    private async Task ScrollToBottom()
    {
        await Js.InvokeVoidAsync("scrollToBottom");
    }

    private static string EncodeHtmlTags(string text)
    {
        return text.Replace("<", "&lt;").Replace(">", "&gt;");
    }
}